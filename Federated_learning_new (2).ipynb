{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from opacus.validators import ModuleValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet18(num_classes=10):\n",
    "    model = torchvision.models.resnet18(num_classes=num_classes)\n",
    "    errors = ModuleValidator.validate(model, strict=False)\n",
    "    errors[-5:]\n",
    "    model = ModuleValidator.fix(model)\n",
    "    ModuleValidator.validate(model, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = ModuleValidator.validate(model, strict=False)\n",
    "# errors[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModuleValidator.fix(model)\n",
    "# ModuleValidator.validate(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "Batch_sz=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_clients,MEAN,STD_DEV,Batch_Size):\n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(MEAN,STD_DEV),])\n",
    "\n",
    "    train_dataset=torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "    test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False,transform=transform)\n",
    "    print(len(train_dataset))\n",
    "\n",
    "    data_size=len(train_dataset)//num_clients\n",
    "    client_datasets=random_split(train_dataset,[data_size]*num_clients)\n",
    "\n",
    "    client_loaders=[DataLoader(ds,batch_size=Batch_Size,shuffle=True) for ds in client_datasets]\n",
    "    test_loader=DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)\n",
    "    \n",
    "    return client_loaders, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 60.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 150\n",
    "MAX_PHYSICAL_BATCH_SIZE = 64\n",
    "LR = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_private(model,train_loader,ePOCHS,ePSILON,dELTA,mAX_GRAD_NORM):\n",
    "#     privacy_engine = PrivacyEngine()\n",
    "#     optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "#     model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "#         module=model,\n",
    "#         optimizer=optimizer,\n",
    "#         data_loader=train_loader,\n",
    "#         epochs=ePOCHS,\n",
    "#         target_epsilon=ePSILON,\n",
    "#         target_delta=dELTA,\n",
    "#         max_grad_norm=mAX_GRAD_NORM,\n",
    "#     )\n",
    "#     print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")\n",
    "#     return model, optimizer, train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_client(model, train_loader, ePSILON,dELTA,mAX_GRAD_NORM,epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=epoch,\n",
    "        target_epsilon=ePSILON,\n",
    "        target_delta=dELTA,\n",
    "        max_grad_norm=mAX_GRAD_NORM,\n",
    "    )\n",
    "    print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss +=criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_models1(models,device):\n",
    "#     averaged_model = create_resnet18()\n",
    "\n",
    "#     averaged_model = averaged_model.to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for param in averaged_model.parameters():\n",
    "#             param.data.zero_()\n",
    "            \n",
    "#         for model in models:\n",
    "#             for param_avg, param_model in zip(averaged_model.parameters(), model.parameters()):\n",
    "#                 param_avg.data += param_model.data\n",
    "                \n",
    "#         # Divide by number of models\n",
    "#         for param in averaged_model.parameters():\n",
    "#             param.data /= len(models)\n",
    "    \n",
    "#     return averaged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "Batch_sz=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramet_stor(client_models,client_loaders,device,num_clients=2,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz,ePOCHS=EPOCHS):\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # client_loaders, test_loader = load_data(num_clients=num_clients,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz)\n",
    "    # client_models = [create_resnet18().to(device) for _ in range(num_clients)]\n",
    "\n",
    "    client_parameters = []\n",
    "    for client_id, (model, loader) in enumerate(zip(client_models, client_loaders)):\n",
    "        print(f\"\\nTraining Client {client_id + 1}\")\n",
    "        # model, optimizer, loader=make_private(model,loader,ePOCHS=EPOCHS,ePSILON=EPSILON,dELTA=DELTA,mAX_GRAD_NORM=MAX_GRAD_NORM)\n",
    "        train_client(model=model, train_loader=loader, epoch=EPOCHS,ePSILON=EPSILON,dELTA=DELTA,mAX_GRAD_NORM=MAX_GRAD_NORM,device=device)\n",
    "        client_parameters.append([param.data.clone() for param in model.parameters()])\n",
    "        for param in model.parameters():\n",
    "            param.data.zero_()\n",
    "    return client_parameters, client_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_models(models,client_parameters):\n",
    "    averaged_model = create_resnet18()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    averaged_model = averaged_model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for param in averaged_model.parameters():\n",
    "            param.data.zero_()\n",
    "            \n",
    "        for param_avg, param_list in zip(averaged_model.parameters(), zip(*client_parameters)):\n",
    "            param_avg.data.copy_(sum(p for p in param_list) / len(models))\n",
    "    \n",
    "    return averaged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_params, models = paramet_stor()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged_model = average_models(models,client_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(num_clients=10, num_rounds=5,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz,ePOCHS=EPOCHS,ePSILON=EPSILON,dELTA=DELTA,mAX_GRAD_NORM=MAX_GRAD_NORM):\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    client_loaders, test_loader = load_data(num_clients=num_clients,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz)\n",
    "    \n",
    "    # Initialize models\n",
    "    \n",
    "    super_model = create_resnet18().to(device)\n",
    "    \n",
    "    # Track metrics\n",
    "    round_accuracies = []\n",
    "    \n",
    "    for round in range(num_rounds):\n",
    "        print(f\"\\n=== Federated Learning Round {round + 1}/{num_rounds} ===\")\n",
    "\n",
    "        client_models = [create_resnet18().to(device) for _ in range(num_clients)]\n",
    "        for model in client_models:\n",
    "            model.load_state_dict(super_model.state_dict())\n",
    "        \n",
    "        # Train each client model\n",
    "        client_params, client_models=paramet_stor(client_models=client_models,client_loaders=client_loaders,device=device,num_clients=10,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz,ePOCHS=EPOCHS)\n",
    "            \n",
    "        # Average models\n",
    "        super_model = average_models( client_models,client_params)\n",
    "        \n",
    "        # Evaluate super model\n",
    "        test_loss, test_accuracy = evaluate(super_model, test_loader, device)\n",
    "        round_accuracies.append(test_accuracy)\n",
    "        print(f\"\\nSuper Model - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # # Update client models with averaged weights\n",
    "        for model in client_models:\n",
    "            model.load_state_dict(super_model.state_dict())\n",
    "        \n",
    "        # Evaluate individual clients\n",
    "        print(\"\\nClient Models Performance:\")\n",
    "        for client_id, model in enumerate(client_models):\n",
    "            loss, accuracy = evaluate(model, test_loader, device)\n",
    "            print(f\"Client {client_id + 1} - Test Accuracy: {accuracy:.2f}%\")\n",
    "        del client_models\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(\"Round-wise Super Model Accuracies:\")\n",
    "    for round, acc in enumerate(round_accuracies, 1):\n",
    "        print(f\"Round {round}: {acc:.2f}%\")\n",
    "    print(f\"Final Super Model Accuracy: {round_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def federated_learning(num_clients=10, num_rounds=5,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz,ePOCHS=EPOCHS,ePSILON=EPSILON,dELTA=DELTA,mAX_GRAD_NORM=MAX_GRAD_NORM):\n",
    "#     # Set device\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Load data\n",
    "#     client_loaders, test_loader = load_data(num_clients=num_clients,MEAN=CIFAR10_MEAN,STD_DEV=CIFAR10_STD_DEV,Batch_Size=Batch_sz)\n",
    "    \n",
    "#     # Initialize models\n",
    "#     client_models = [create_resnet18().to(device) for _ in range(num_clients)]\n",
    "#     super_model = create_resnet18().to(device)\n",
    "    \n",
    "#     # Track metrics\n",
    "#     round_accuracies = []\n",
    "    \n",
    "#     for round in range(num_rounds):\n",
    "#         print(f\"\\n=== Federated Learning Round {round + 1}/{num_rounds} ===\")\n",
    "        \n",
    "#         # Train each client model\n",
    "#         for client_id, (model, loader) in enumerate(zip(client_models, client_loaders)):\n",
    "#             print(f\"\\nTraining Client {client_id + 1}\")\n",
    "#             model, optimizer, loader=make_private(model,loader,ePOCHS=EPOCHS,ePSILON=EPSILON,dELTA=DELTA,mAX_GRAD_NORM=MAX_GRAD_NORM)\n",
    "#             train_client(model, loader, optimizer, EPOCHS,device)\n",
    "            \n",
    "            \n",
    "#         # Average models\n",
    "#         super_model = average_models(client_models,device)\n",
    "        \n",
    "#         # Evaluate super model\n",
    "#         test_loss, test_accuracy = evaluate(super_model, test_loader, device)\n",
    "#         round_accuracies.append(test_accuracy)\n",
    "#         print(f\"\\nSuper Model - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        \n",
    "#         # Update client models with averaged weights\n",
    "#         for model in client_models:\n",
    "#             model.load_state_dict(super_model.state_dict())\n",
    "        \n",
    "#         # Evaluate individual clients\n",
    "#         print(\"\\nClient Models Performance:\")\n",
    "#         for client_id, model in enumerate(client_models):\n",
    "#             loss, accuracy = evaluate(model, test_loader, device)\n",
    "#             print(f\"Client {client_id + 1} - Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "#     # Print final results\n",
    "#     print(\"\\n=== Final Results ===\")\n",
    "#     print(\"Round-wise Super Model Accuracies:\")\n",
    "#     for round, acc in enumerate(round_accuracies, 1):\n",
    "#         print(f\"Round {round}: {acc:.2f}%\")\n",
    "#     print(f\"Final Super Model Accuracy: {round_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "\n",
      "=== Federated Learning Round 1/3 ===\n",
      "\n",
      "Training Client 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sigma=0.5458641052246094 and C=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Epoch: 150 \tLoss: 24.783700 Acc@1: 9.524052 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 14.510549 Acc@1: 9.965573 (ε = 6.25, δ = 1e-05)\n",
      "\n",
      "Training Client 2\n",
      "Using sigma=0.5458641052246094 and C=1.2\n",
      "\tTrain Epoch: 150 \tLoss: 24.164040 Acc@1: 9.869386 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 14.354968 Acc@1: 10.032081 (ε = 6.29, δ = 1e-05)\n",
      "\n",
      "Super Model - Test Loss: 0.0053, Test Accuracy: 10.00%\n",
      "\n",
      "Client Models Performance:\n",
      "Client 1 - Test Accuracy: 10.00%\n",
      "Client 2 - Test Accuracy: 10.00%\n",
      "\n",
      "=== Federated Learning Round 2/3 ===\n",
      "\n",
      "Training Client 1\n",
      "Using sigma=0.5458641052246094 and C=1.2\n",
      "\tTrain Epoch: 150 \tLoss: 9.884464 Acc@1: 10.094872 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 6.137544 Acc@1: 9.988227 (ε = 6.29, δ = 1e-05)\n",
      "\n",
      "Training Client 2\n",
      "Using sigma=0.5458641052246094 and C=1.2\n",
      "\tTrain Epoch: 150 \tLoss: 10.360314 Acc@1: 10.109482 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 6.366293 Acc@1: 10.155838 (ε = 6.25, δ = 1e-05)\n",
      "\n",
      "Super Model - Test Loss: 0.0046, Test Accuracy: 10.00%\n",
      "\n",
      "Client Models Performance:\n",
      "Client 1 - Test Accuracy: 10.00%\n",
      "Client 2 - Test Accuracy: 10.00%\n",
      "\n",
      "=== Federated Learning Round 3/3 ===\n",
      "\n",
      "Training Client 1\n",
      "Using sigma=0.5458641052246094 and C=1.2\n",
      "\tTrain Epoch: 150 \tLoss: 4.097321 Acc@1: 10.197299 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 3.212180 Acc@1: 10.370805 (ε = 6.29, δ = 1e-05)\n",
      "\n",
      "Training Client 2\n",
      "Using sigma=0.5458641052246094 and C=1.2\n",
      "\tTrain Epoch: 150 \tLoss: 3.791207 Acc@1: 10.317591 (ε = 5.36, δ = 1e-05)\n",
      "\tTrain Epoch: 150 \tLoss: 3.055209 Acc@1: 10.686438 (ε = 6.29, δ = 1e-05)\n",
      "\n",
      "Super Model - Test Loss: 0.0046, Test Accuracy: 10.71%\n",
      "\n",
      "Client Models Performance:\n",
      "Client 1 - Test Accuracy: 10.71%\n",
      "Client 2 - Test Accuracy: 10.71%\n",
      "\n",
      "=== Final Results ===\n",
      "Round-wise Super Model Accuracies:\n",
      "Round 1: 10.00%\n",
      "Round 2: 10.00%\n",
      "Round 3: 10.71%\n",
      "Final Super Model Accuracy: 10.71%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    federated_learning(num_clients=2, num_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     federated_learning(num_clients=10, num_rounds=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
